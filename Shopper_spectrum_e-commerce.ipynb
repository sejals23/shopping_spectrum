{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"collapsed_sections":["vncDsAP0Gaoa","FJNUwmbgGyua","w6K7xa23Elo4","yQaldy8SH6Dl","mDgbUHAGgjLW","O_i_v8NEhb9l","HhfV-JJviCcP","Y3lxredqlCYt","3RnN4peoiCZX","x71ZqKXriCWQ","7hBIi_osiCS2","JlHwYmJAmNHm","35m5QtbWiB9F","PoPl-ycgm1ru","H0kj-8xxnORC","nA9Y7ga8ng1Z","PBTbrJXOngz2","u3PMJOP6ngxN","dauF4eBmngu3","bKJF3rekwFvQ","MSa1f5Uengrz","GF8Ens_Soomf","0wOQAZs5pc--","K5QZ13OEpz2H","lQ7QKXXCp7Bj","448CDAPjqfQr","KSlN3yHqYklG","t6dVpIINYklI","ijmpgYnKYklI","-JiQyfWJYklI","EM7whBJCYoAo","fge-S5ZAYoAp","85gYPyotYoAp","RoGjAbkUYoAp","4Of9eVA-YrdM","iky9q4vBYrdO","F6T5p64dYrdO","y-Ehk30pYrdP","bamQiAODYuh1","QHF8YVU7Yuh3","GwzvFGzlYuh3","qYpmQ266Yuh3","OH-pJp9IphqM","bbFf2-_FphqN","_ouA3fa0phqN","Seke61FWphqN","PIIx-8_IphqN","t27r6nlMphqO","r2jJGEOYphqO","b0JNsNcRphqO","BZR9WyysphqO","jj7wYXLtphqO","eZrbJ2SmphqO","rFu4xreNphqO","YJ55k-q6phqO","gCFgpxoyphqP","OVtJsKN_phqQ","lssrdh5qphqQ","U2RJ9gkRphqQ","1M8mcRywphqQ","tgIPom80phqQ","JMzcOPDDphqR","x-EpHcCOp1ci","X_VqEhTip1ck","8zGJKyg5p1ck","PVzmfK_Ep1ck","n3dbpmDWp1ck","ylSl6qgtp1ck","ZWILFDl5p1ck","M7G43BXep1ck","Ag9LCva-p1cl","E6MkPsBcp1cl","2cELzS2fp1cl","3MPXvC8up1cl","NC_X3p0fY2L0","UV0SzAkaZNRQ","YPEH6qLeZNRQ","q29F0dvdveiT","EXh0U9oCveiU","22aHeOlLveiV","g-ATYxFrGrvw","Yfr_Vlr8HBkt","8yEUt7NnHlrM","tEA2Xm5dHt1r","I79__PHVH19G","Ou-I18pAyIpj","fF3858GYyt-u","4_0_7-oCpUZd","hwyV_J3ipUZe","3yB-zSqbpUZe","dEUvejAfpUZe","Fd15vwWVpUZf","bn_IUdTipZyH","49K5P_iCpZyH","Nff-vKELpZyI","kLW572S8pZyI","dWbDXHzopZyI","yLjJCtPM0KBk","xiyOF9F70UgQ","7wuGOrhz0itI","id1riN9m0vUs","578E2V7j08f6","89xtkJwZ18nB","67NQN5KX2AMe","Iwf50b-R2tYG","GMQiZwjn3iu7","WVIkgGqN3qsr","XkPnILGE3zoT","Hlsf0x5436Go","mT9DMSJo4nBL","c49ITxTc407N","OeJFEK0N496M","9ExmJH0g5HBk","cJNqERVU536h","k5UmGsbsOxih","T0VqWOYE6DLQ","qBMux9mC6MCf","-oLEiFgy-5Pf","C74aWNz2AliB","2DejudWSA-a0","pEMng2IbBLp7","rAdphbQ9Bhjc","TNVZ9zx19K6k","nqoHp30x9hH9","rMDnDkt2B6du","yiiVWRdJDDil","1UUpS68QDMuG","kexQrXU-DjzY","T5CmagL3EC8N","BhH2vgX9EjGr","qjKvONjwE8ra","P1XJ9OREExlT","VFOzZv6IFROw","TIqpNgepFxVj","VfCC591jGiD4","OB4l2ZhMeS1U","ArJBuiUVfxKd","4qY1EAkEfxKe","PiV4Ypx8fxKe","TfvqoZmBfxKf","dJ2tPlVmpsJ0","JWYfwnehpsJ1","-jK_YjpMpsJ2","HAih1iBOpsJ2","zVGeBEFhpsJ2","bmKjuQ-FpsJ3","Fze-IPXLpx6K","7AN1z2sKpx6M","9PIHJqyupx6M","_-qAgymDpx6N","Z-hykwinpx6N","h_CCil-SKHpo","cBFFvTBNJzUa","HvGl1hHyA_VK","EyNgTHvd2WFk","KH5McJBi2d8v","iW_Lq9qf2h6X","-Kee-DAl2viO","gCX9965dhzqZ","gIfDvo9L0UH2"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Project Name**    -\n","\n"],"metadata":{"id":"vncDsAP0Gaoa"}},{"cell_type":"markdown","source":["##### **Project Type**    - Unsupervised\n","##### **Contribution**    - Individual\n","##### **Name**            - Sejal\n"],"metadata":{"id":"beRrZCGUAJYm"}},{"cell_type":"markdown","source":["# **Project Summary -**"],"metadata":{"id":"FJNUwmbgGyua"}},{"cell_type":"markdown","source":["\n","The goal of this project was to perform **customer segmentation** using **unsupervised machine learning techniques** to better understand purchasing behaviors and improve business strategies. We utilized **RFM analysis (Recency, Frequency, Monetary)** combined with **K-Means clustering** to identify customer segments from the given dataset.  \n","\n","---\n","\n","### **1. Data Preprocessing**\n","The dataset contained customer transaction data with fields like *InvoiceNo, InvoiceDate, CustomerID, Quantity, UnitPrice,* and *Country*. We performed the following preprocessing steps:\n","- Removed missing values (e.g., customers without a CustomerID).\n","- Removed duplicate rows and canceled transactions (InvoiceNo starting with 'C').\n","- Created a **TotalPrice** feature = *Quantity × UnitPrice* to represent the total monetary value of each transaction.\n","- Converted the **InvoiceDate** column to datetime format for time-based calculations.\n","\n","---\n","\n","### **2. RFM Analysis**\n","We derived **RFM metrics** for each customer:\n","- **Recency:** Days since the last purchase (Latest date in dataset − last purchase date).\n","- **Frequency:** Total number of unique transactions (invoices).\n","- **Monetary:** Total amount spent by the customer.  \n","\n","We grouped data by `CustomerID` to calculate RFM values. These metrics provided a foundation to differentiate customers based on their purchase patterns.\n","\n","---\n","\n","### **3. Feature Scaling**\n","As RFM values vary greatly in scale, we standardized them using **StandardScaler**:\n","- Mean = 0, Standard Deviation = 1 for each feature.\n","- This ensured fair comparison during clustering.\n","\n","Normalization was avoided as it could distort differences in frequency and monetary values, which are important for segmentation.\n","\n","---\n","\n","### **4. Clustering**\n","We used the **K-Means clustering algorithm** because it is simple, efficient, and works well with numerical data like RFM scores.\n","\n","#### **Choosing the Optimal Number of Clusters**\n","- **Elbow Method (WCSS):** Showed a clear \"elbow\" at **k = 4**, suggesting that four clusters best balance compactness and separation.\n","- **Silhouette Score:** Confirmed that k = 4 provided a good balance between intra-cluster similarity and inter-cluster difference.\n","\n","---\n","\n","### **5. Cluster Insights**\n","We identified **4 distinct customer segments**:\n","1. **High-value frequent customers:** Low Recency (recent purchases), high Frequency, high Monetary value – loyal and profitable customers.\n","2. **Moderate customers:** Average across all three metrics – potential for upselling and engagement.\n","3. **Occasional/one-time customers:** High Recency (not purchased recently), low Frequency – need reactivation strategies.\n","4. **Low-value or dormant customers:** High Recency, low Frequency, low Monetary – at risk of churn.\n","\n","---\n","\n","### **6. Data Visualization & Insights**\n","We created visualizations for deeper understanding:\n","- **Transaction volume by country:** Revealed that the majority of sales occurred in the United Kingdom, providing insights for market focus.\n","- **Top 10 best-selling products:** Helped identify high-demand items to maintain adequate stock.\n","- **Purchase trends over time:** Showed seasonal and time-based purchasing patterns.\n","- **Monetary value distribution:** Indicated that most transactions were of low to medium value.\n","\n","These insights can help businesses improve product planning, marketing strategies, and revenue generation.\n","\n","---\n","\n","### **7. Business Impact**\n","- **Customer Retention:** By identifying loyal customers, businesses can reward them with exclusive offers.\n","- **Churn Reduction:** Dormant customers can be targeted with personalized reactivation campaigns.\n","- **Optimized Marketing Spend:** Resources can be allocated more efficiently by focusing on high-value segments.\n","\n","---\n","\n"],"metadata":{"id":"F6v_1wHtG2nS"}},{"cell_type":"markdown","source":["# **GitHub Link -**"],"metadata":{"id":"w6K7xa23Elo4"}},{"cell_type":"markdown","source":["Provide your GitHub Link here."],"metadata":{"id":"h1o69JH3Eqqn"}},{"cell_type":"markdown","source":["# **Problem Statement**\n"],"metadata":{"id":"yQaldy8SH6Dl"}},{"cell_type":"markdown","source":["The global e-commerce industry generates vast amounts of transaction data daily, offering valuable insights into customer purchasing behaviors. Analyzing this data is essential for identifying meaningful customer segments and recommending relevant products to enhance customer experience and drive business growth. This project aims to examine transaction data from an online retail business to uncover patterns in customer purchase behavior, segment customers based on Recency, Frequency, and Monetary (RFM) analysis, and develop a product recommendation system using collaborative filtering techniques."],"metadata":{"id":"DpeJGUA3kjGy"}},{"cell_type":"markdown","source":["# ***Let's Begin !***"],"metadata":{"id":"O_i_v8NEhb9l"}},{"cell_type":"markdown","source":["## ***1. Know Your Data***"],"metadata":{"id":"HhfV-JJviCcP"}},{"cell_type":"markdown","source":["### Import Libraries"],"metadata":{"id":"Y3lxredqlCYt"}},{"cell_type":"code","source":["# Import Libraries\n","import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.cluster import KMeans\n","from mpl_toolkits.mplot3d import Axes3D\n","\n"],"metadata":{"id":"M8Vqi-pPk-HR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Dataset Loading"],"metadata":{"id":"3RnN4peoiCZX"}},{"cell_type":"code","source":["# Load Dataset\n","from google.colab import drive\n","drive.mount('/content/drive')\n","df=pd.read_csv('/content/drive/MyDrive/E-commerce/online_retail.csv')"],"metadata":{"id":"4CkvbW_SlZ_R"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Dataset First View"],"metadata":{"id":"x71ZqKXriCWQ"}},{"cell_type":"code","source":["# Dataset First Look\n","df.head()"],"metadata":{"id":"LWNFOSvLl09H"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Dataset Rows & Columns count"],"metadata":{"id":"7hBIi_osiCS2"}},{"cell_type":"code","source":["# Dataset Rows & Columns count\n","print(\"Total Rows:\", df.shape[0])\n","print(\"Total Columns:\", df.shape[1])\n"],"metadata":{"id":"Kllu7SJgmLij"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Dataset Information"],"metadata":{"id":"JlHwYmJAmNHm"}},{"cell_type":"code","source":["# Dataset Info\n","df.info()"],"metadata":{"id":"e9hRXRi6meOf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Duplicate Values"],"metadata":{"id":"35m5QtbWiB9F"}},{"cell_type":"code","source":["# Dataset Duplicate Value Count\n","duplicate_count = df.duplicated().sum()\n","print(\"Number of duplicate rows:\", duplicate_count)\n"],"metadata":{"id":"1sLdpKYkmox0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Missing Values/Null Values"],"metadata":{"id":"PoPl-ycgm1ru"}},{"cell_type":"code","source":["# Missing Values/Null Values Count\n","missing_values = df.isnull().sum()\n","\n","print(\"Missing/Null Values Count per Column:\")\n","print(missing_values)\n"],"metadata":{"id":"GgHWkxvamxVg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sns.set(style=\"whitegrid\")\n","\n","# Bar plot for missing values count\n","missing_values = df.isnull().sum()\n","missing_values = missing_values[missing_values > 0]\n","\n","plt.figure(figsize=(8,4))\n","sns.barplot(x=missing_values.index, y=missing_values.values, palette=\"mako\")\n","plt.title(\"Missing Values Count per Column\")\n","plt.ylabel(\"Count of Missing Values\")\n","plt.xlabel(\"Columns\")\n","plt.xticks(rotation=30)\n","plt.show()\n","\n"],"metadata":{"id":"3q5wnI3om9sJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### What did you know about your dataset?\n","\n"],"metadata":{"id":"H0kj-8xxnORC"}},{"cell_type":"markdown","source":["1. The dataset contains **541,909 rows** and **8 columns**.\n","2. It includes details of online retail transactions such as:\n","   - Invoice number  \n","   - Product code  \n","   - Product description  \n","   - Quantity purchased  \n","   - Invoice date  \n","   - Price per item  \n","   - Customer ID  \n","   - Country\n","3. Two columns have missing values:\n","   - **CustomerID**: 135,080 missing values (~25% of the dataset)\n","   - **Description**: 1,454 missing values (<1% of the dataset)\n","4. The dataset may contain **duplicate rows** that need to be cleaned.\n","5. **Quantity** can have negative values, usually indicating product returns.\n","6. **UnitPrice** may have zero or invalid values, which need to be checked and handled.\n","7. This dataset can be used for several business insights:\n","   - **Customer Segmentation** using RFM (Recency, Frequency, Monetary) analysis  \n","   - **Product Recommendations** through collaborative filtering  \n","   - Identifying top-selling products, return patterns, and sales by country  \n","   - Supporting targeted marketing campaigns and inventory management\n"],"metadata":{"id":"gfoNAAC-nUe_"}},{"cell_type":"markdown","source":["## ***2. Understanding Your Variables***"],"metadata":{"id":"nA9Y7ga8ng1Z"}},{"cell_type":"code","source":["# Dataset Columns\n","df.shape[1]"],"metadata":{"id":"j7xfkqrt5Ag5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Dataset Describe\n","df.describe()"],"metadata":{"id":"DnOaZdaE5Q5t"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Variables Description"],"metadata":{"id":"PBTbrJXOngz2"}},{"cell_type":"markdown","source":["\n","| **Column Name** | **Description** |\n","|-----------------|-----------------|\n","| **InvoiceNo**   | Transaction number for each purchase (unique for each invoice) |\n","| **StockCode**   | Unique product/item code |\n","| **Description** | Name/description of the product |\n","| **Quantity**    | Number of products purchased (can be negative for returns) |\n","| **InvoiceDate** | Date and time of the transaction (2022–2023) |\n","| **UnitPrice**   | Price per product/item |\n","| **CustomerID**  | Unique identifier for each customer |\n","| **Country**     | Country where the customer is based |\n"],"metadata":{"id":"aJV4KIxSnxay"}},{"cell_type":"markdown","source":["### Check Unique Values for each variable."],"metadata":{"id":"u3PMJOP6ngxN"}},{"cell_type":"code","source":["# Check Unique Values for each variable.\n","for col in df.columns:\n","    print(f\"{col} → {df[col].nunique()} unique values\")\n"],"metadata":{"id":"zms12Yq5n-jE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"],"metadata":{"id":"GF8Ens_Soomf"}},{"cell_type":"markdown","source":["#### Chart - 1"],"metadata":{"id":"0wOQAZs5pc--"}},{"cell_type":"code","source":["# Chart - 1 visualization code\n","\n","# Group data by country and count transactions\n","country_txn = df.groupby('Country')['InvoiceNo'].nunique().sort_values(ascending=False)\n","\n","# Plot transaction volume by country\n","plt.figure(figsize=(15,6))\n","sns.barplot(x=country_txn.index, y=country_txn.values, palette=\"viridis\")\n","\n","plt.title(\"Transaction Volume by Country\", fontsize=14)\n","plt.ylabel(\"Number of Transactions\")\n","plt.xlabel(\"Country\")\n","plt.xticks(rotation=75)\n","plt.show()\n"],"metadata":{"id":"7v_ESjsspbW7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. Why did you pick the specific chart?"],"metadata":{"id":"K5QZ13OEpz2H"}},{"cell_type":"markdown","source":["I used a **bar chart** because it is the most effective way to compare the transaction volumes across different countries. Each country is clearly represented, and the relative transaction numbers can be easily compared at a glance.\n"],"metadata":{"id":"XESiWehPqBRc"}},{"cell_type":"markdown","source":["##### 2. What is/are the insight(s) found from the chart?"],"metadata":{"id":"lQ7QKXXCp7Bj"}},{"cell_type":"markdown","source":["- **United Kingdom** has an overwhelmingly higher number of transactions compared to all other countries.  \n","- Countries like **Germany, France, and EIRE** have moderate transaction volumes, while most other countries have very few transactions.  \n","- The dataset is highly **skewed towards the UK market**.\n","\n"],"metadata":{"id":"C_j1G7yiqdRP"}},{"cell_type":"markdown","source":["##### 3. Will the gained insights help creating a positive business impact?\n","Are there any insights that lead to negative growth? Justify with specific reason."],"metadata":{"id":"448CDAPjqfQr"}},{"cell_type":"markdown","source":[" **Yes**, the insights can positively impact business strategy:\n","  - Since the UK contributes the highest volume, focusing marketing campaigns and loyalty programs in the UK can yield higher returns.  \n","  - Countries with low transactions could be targeted with awareness campaigns, discounts, or partnerships to increase sales.\n","---\n","- The skewness in transactions suggests the business is **overly dependent on one market (UK)**.  \n","- Any disruption in the UK market could negatively impact overall revenue.  \n","- It is important to **diversify sales across multiple countries** to reduce dependency and risk.\n"],"metadata":{"id":"3cspy4FjqxJW"}},{"cell_type":"markdown","source":["#### Chart - 2"],"metadata":{"id":"KSlN3yHqYklG"}},{"cell_type":"code","source":["# Chart - 2 visualization code\n","top_products = (\n","    df.groupby('Description')['Quantity']\n","    .sum()\n","    .sort_values(ascending=False)\n","    .head(10)\n",")\n","\n","# Plot chart\n","plt.figure(figsize=(12,6))\n","sns.barplot(x=top_products.values, y=top_products.index, palette=\"mako\")\n","plt.title(\"Top 10 Best-Selling Products\", fontsize=14)\n","plt.xlabel(\"Total Quantity Sold\")\n","plt.ylabel(\"Product Description\")\n","plt.show()\n"],"metadata":{"id":"R4YgtaqtYklH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. Why did you pick the specific chart?"],"metadata":{"id":"t6dVpIINYklI"}},{"cell_type":"markdown","source":["I used a **horizontal bar chart** because it clearly shows the total quantity sold for each product.  \n","This format makes it easy to rank products from the highest-selling to the lowest-selling.\n","\n"],"metadata":{"id":"5aaW0BYyYklI"}},{"cell_type":"markdown","source":["##### 2. What is/are the insight(s) found from the chart?"],"metadata":{"id":"ijmpgYnKYklI"}},{"cell_type":"markdown","source":["- **\"WORLD WAR 2 GLIDERS ASSTD DESIGNS\"** is the highest-selling product by a significant margin.  \n","- Products like **\"JUMBO BAG RED RETROSPOT\"**, **\"ASSORTED COLOUR BIRD ORNAMENT\"**, and **\"POPCORN HOLDER\"** also have very high sales volumes.  \n","- The sales distribution shows that a few products dominate overall sales, while others sell in smaller volumes.\n","\n"],"metadata":{"id":"PSx9atu2YklI"}},{"cell_type":"markdown","source":["##### 3. Will the gained insights help creating a positive business impact?\n","Are there any insights that lead to negative growth? Justify with specific reason."],"metadata":{"id":"-JiQyfWJYklI"}},{"cell_type":"markdown","source":["- **Yes**, these insights help the business focus on:\n","  - Ensuring sufficient inventory for top-selling products to avoid stock-outs.  \n","  - Identifying potential products to feature in promotions or bundle offers.  \n","  - Understanding product preferences for better forecasting and procurement.\n","\n","---\n","- There is a risk of **over-dependence on a small number of products**.  \n","- If demand for the top products falls or if supply chain issues arise, sales could be heavily impacted.  \n","- Diversifying marketing strategies to boost the sales of mid-tier products can reduce risk.\n"],"metadata":{"id":"BcBbebzrYklV"}},{"cell_type":"markdown","source":["#### Chart - 3"],"metadata":{"id":"EM7whBJCYoAo"}},{"cell_type":"code","source":["# Chart - 3 visualization code\n","df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])\n","\n","# Create a new column for date (ignoring time)\n","df['Date'] = df['InvoiceDate'].dt.date\n","\n","# Group by date and count total transactions\n","daily_trend = df.groupby('Date')['InvoiceNo'].nunique()\n","\n","# Plot purchase trends over time\n","plt.figure(figsize=(14,6))\n","sns.lineplot(x=daily_trend.index, y=daily_trend.values, color='blue')\n","plt.title(\"Purchase Trends Over Time\", fontsize=14)\n","plt.xlabel(\"Date\")\n","plt.ylabel(\"Number of Transactions\")\n","plt.xticks(rotation=45)\n","plt.tight_layout()\n","plt.show()\n"],"metadata":{"id":"t6GMdE67YoAp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. Why did you pick the specific chart?"],"metadata":{"id":"fge-S5ZAYoAp"}},{"cell_type":"markdown","source":["I selected a **line chart** because it effectively shows how the number of transactions changes over time.  \n","This type of chart makes it easy to observe fluctuations, patterns, and seasonality in purchases.\n"],"metadata":{"id":"5dBItgRVYoAp"}},{"cell_type":"markdown","source":["##### 2. What is/are the insight(s) found from the chart?"],"metadata":{"id":"85gYPyotYoAp"}},{"cell_type":"markdown","source":["- Transaction volumes show a **lot of fluctuations**, with some sharp spikes on certain dates.  \n","- There is an overall **upward trend** in the latter part of the year (around September to November).  \n","- Peaks may be associated with **festive seasons or special promotions**, while the dips could indicate low shopping periods.\n"],"metadata":{"id":"4jstXR6OYoAp"}},{"cell_type":"markdown","source":["##### 3. Will the gained insights help creating a positive business impact?\n","Are there any insights that lead to negative growth? Justify with specific reason."],"metadata":{"id":"RoGjAbkUYoAp"}},{"cell_type":"markdown","source":["- **Yes**, these insights can help in:\n","  - Planning inventory and supply chain around peak seasons to avoid stock-outs.  \n","  - Scheduling marketing campaigns during low-transaction periods to boost sales.  \n","  - Identifying high-revenue days and replicating the strategies that worked.\n","\n","---\n","- The **frequent dips** in transactions could indicate missed sales opportunities or periods of low customer engagement.  \n","- Businesses should investigate the reasons behind these dips (e.g., stock issues, reduced marketing) and take corrective action.\n"],"metadata":{"id":"zfJ8IqMcYoAp"}},{"cell_type":"markdown","source":["#### Chart - 4"],"metadata":{"id":"4Of9eVA-YrdM"}},{"cell_type":"code","source":["# Chart - 4 visualization code\n","\n","# Create a new column for total monetary value of each line item\n","df['TotalPrice'] = df['Quantity'] * df['UnitPrice']\n","\n","#  Monetary distribution per transaction\n","transaction_value = df.groupby('InvoiceNo')['TotalPrice'].sum()\n","\n","plt.figure(figsize=(15,5))\n","sns.histplot(transaction_value, bins=50, kde=True, color=\"purple\")\n","plt.title(\" Monetary Distribution per Transaction\", fontsize=14)\n","plt.xlabel(\"Transaction Value\")\n","plt.ylabel(\"Frequency\")\n","plt.xlim(0, transaction_value.quantile(0.95))  # Remove extreme outliers\n","plt.show()\n"],"metadata":{"id":"irlUoxc8YrdO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. Why did you pick the specific chart?"],"metadata":{"id":"iky9q4vBYrdO"}},{"cell_type":"markdown","source":["I selected an **area plot** because it shows the distribution of transaction values clearly.  \n","It helps visualize how frequently certain monetary values occur across transactions.\n"],"metadata":{"id":"aJRCwT6DYrdO"}},{"cell_type":"markdown","source":["##### 2. What is/are the insight(s) found from the chart?"],"metadata":{"id":"F6T5p64dYrdO"}},{"cell_type":"markdown","source":["- Most transactions fall in the **mid-range of transaction values** (around 800 units).  \n","- There are fewer transactions with very low or very high transaction values.  \n","- This indicates a **balanced spending pattern**, where customers typically purchase moderate amounts.\n"],"metadata":{"id":"Xx8WAJvtYrdO"}},{"cell_type":"markdown","source":["##### 3. Will the gained insights help creating a positive business impact?\n","Are there any insights that lead to negative growth? Justify with specific reason."],"metadata":{"id":"y-Ehk30pYrdP"}},{"cell_type":"markdown","source":["- **Yes**, these insights help businesses understand the average spending behavior and set targeted strategies:\n","  - Designing bundles or offers around the mid-value spending range can increase revenue.  \n","  - Identify high-value customers (outliers) and create **loyalty programs** for them.\n","\n","---\n","- If very few customers make high-value purchases, the business may be missing out on opportunities to **upsell or cross-sell**.  \n","- Offering incentives for customers to increase their basket size could mitigate this gap.\n","Do you also want me to write Colab-"],"metadata":{"id":"jLNxxz7MYrdP"}},{"cell_type":"markdown","source":["#### Chart - 5"],"metadata":{"id":"bamQiAODYuh1"}},{"cell_type":"code","source":["# Chart - 5 visualization code\n","\n","# Monetary distribution per customer\n","customer_value = df.groupby('CustomerID')['TotalPrice'].sum()\n","\n","plt.figure(figsize=(12,5))\n","sns.histplot(customer_value, bins=50, kde=True, color=\"green\")\n","plt.title(\" Monetary Distribution per Customer\", fontsize=14)\n","plt.xlabel(\"Customer Lifetime Value\")\n","plt.ylabel(\"Frequency\")\n","plt.xlim(0, customer_value.quantile(0.95))  # Remove extreme outliers\n","plt.show()\n"],"metadata":{"id":"TIJwrbroYuh3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. Why did you pick the specific chart?"],"metadata":{"id":"QHF8YVU7Yuh3"}},{"cell_type":"markdown","source":["This histogram with a line plot clearly shows the **distribution of Customer Lifetime Value (CLV)**.  \n","It helps identify where most customers fall and makes it easy to spot trends or outliers.  \n","\n"],"metadata":{"id":"dcxuIMRPYuh3"}},{"cell_type":"markdown","source":["##### 2. What is/are the insight(s) found from the chart?"],"metadata":{"id":"GwzvFGzlYuh3"}},{"cell_type":"markdown","source":[" Most customers have a **low CLV (0–1500)**.  \n","- Customer count drops sharply as CLV increases.  \n","- Few customers contribute very high CLV, forming a long-tail distribution.  \n","\n"],"metadata":{"id":"uyqkiB8YYuh3"}},{"cell_type":"markdown","source":["##### 3. Will the gained insights help creating a positive business impact?\n","Are there any insights that lead to negative growth? Justify with specific reason."],"metadata":{"id":"qYpmQ266Yuh3"}},{"cell_type":"markdown","source":["Yes. The insights help in:\n","- Identifying trends and customer preferences  \n","- Improving operational efficiency  \n","- Targeting the right audience effectively  \n","- Optimizing resources for better profitability  \n","\n","---\n","Some insights may indicate challenges such as:\n","- Drop in customer retention  \n","- Underperforming products or services  \n","\n","Although these reflect current weaknesses, they **highlight opportunities for improvement**, allowing businesses to correct strategies and prevent further losses.\n"],"metadata":{"id":"_WtzZ_hCYuh4"}},{"cell_type":"markdown","source":["#### Chart - 6"],"metadata":{"id":"OH-pJp9IphqM"}},{"cell_type":"code","source":["# Chart - 6 visualization code\n","#  Boxplots for Quantity and UnitPrice\n","plt.figure(figsize=(14,5))\n","\n","plt.subplot(1,2,1)\n","sns.boxplot(x=df['Quantity'], color=\"skyblue\")\n","plt.title(\"Boxplot - Quantity\")\n","\n","plt.subplot(1,2,2)\n","sns.boxplot(x=df['UnitPrice'], color=\"lightgreen\")\n","plt.title(\"Boxplot - UnitPrice\")\n","\n","plt.show()\n","\n","#  Calculate IQR and find outliers for Quantity\n","Q1 = df['Quantity'].quantile(0.25)\n","Q3 = df['Quantity'].quantile(0.75)\n","IQR = Q3 - Q1\n","\n","lower_bound = Q1 - 1.5*IQR\n","upper_bound = Q3 + 1.5*IQR\n","\n","outliers_quantity = df[(df['Quantity'] < lower_bound) | (df['Quantity'] > upper_bound)]\n","print(f\"Outliers in Quantity: {outliers_quantity.shape[0]} rows\")\n","\n","# Calculate IQR and find outliers for UnitPrice\n","Q1 = df['UnitPrice'].quantile(0.25)\n","Q3 = df['UnitPrice'].quantile(0.75)\n","IQR = Q3 - Q1\n","\n","lower_bound = Q1 - 1.5*IQR\n","upper_bound = Q3 + 1.5*IQR\n","\n","outliers_price = df[(df['UnitPrice'] < lower_bound) | (df['UnitPrice'] > upper_bound)]\n","print(f\"Outliers in UnitPrice: {outliers_price.shape[0]} rows\")\n"],"metadata":{"id":"kuRf4wtuphqN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. Why did you pick the specific chart?"],"metadata":{"id":"bbFf2-_FphqN"}},{"cell_type":"markdown","source":["- A **boxplot** is a powerful tool for detecting outliers in continuous variables.\n","- We selected boxplots for **Quantity** and **UnitPrice** because these features often contain extreme values that can distort statistical calculations and machine learning models.\n","- The boxplot helps visualize the spread of data (median, quartiles, minimum, maximum) and highlights values that fall far outside the typical range.\n","\n"],"metadata":{"id":"loh7H2nzphqN"}},{"cell_type":"markdown","source":["##### 2. What is/are the insight(s) found from the chart?"],"metadata":{"id":"_ouA3fa0phqN"}},{"cell_type":"markdown","source":["- **Quantity:**\n","  - There are significant outliers on both the positive and negative ends.\n","  - Negative values likely indicate **order cancellations or data errors**.\n","  - Positive outliers suggest unusually large orders.\n","- **UnitPrice:**\n","  - Multiple extreme outliers exist, with some prices reaching very high values.\n","  - Negative values are also present, which are unrealistic and could indicate erroneous data entries.\n","\n"],"metadata":{"id":"VECbqPI7phqN"}},{"cell_type":"markdown","source":["##### 3. Will the gained insights help creating a positive business impact?\n","Are there any insights that lead to negative growth? Justify with specific reason."],"metadata":{"id":"Seke61FWphqN"}},{"cell_type":"markdown","source":["- **Yes.**\n","  - Identifying and removing incorrect or extreme values improves the quality of the dataset, leading to more accurate customer segmentation and recommendations.\n","  - Outlier detection prevents skewed RFM scores and incorrect clustering.\n","  \n","- **Negative Growth Possibility:**\n","  - If outliers are ignored, they can lead to **misleading patterns**, such as misclassifying customers as high-value based on erroneous high transaction values.\n","  - It can also distort the calculation of averages and monetary metrics, affecting decision-making.\n","\n","---\n"],"metadata":{"id":"DW4_bGpfphqN"}},{"cell_type":"markdown","source":["## ***5. Data Pre-processing***"],"metadata":{"id":"yLjJCtPM0KBk"}},{"cell_type":"markdown","source":["### 1. Handling Missing Values"],"metadata":{"id":"xiyOF9F70UgQ"}},{"cell_type":"code","source":["# Handling Missing Values & Missing Value Imputation\n","\n","# Drop rows with missing Description (cannot be imputed meaningfully)\n","df = df[~df['Description'].isnull()]\n","\n","# Drop rows with missing CustomerID (critical for customer-level analysis)\n","df = df[~df['CustomerID'].isnull()]\n","\n","# Reset index after dropping rows\n","df.reset_index(drop=True, inplace=True)\n","\n","# Check missing values after handling\n","print(\"\\nMissing values after handling:\\n\", df.isnull().sum())\n","\n"],"metadata":{"id":"iRsAHk1K0fpS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### What all missing value imputation techniques have you used and why did you use those techniques?"],"metadata":{"id":"7wuGOrhz0itI"}},{"cell_type":"markdown","source":["In our dataset, we handled missing values using the **row removal technique** for specific columns instead of imputing values. Here's why:\n","\n","---\n","\n","#### **Description Column**\n","- **Issue:** 1,454 missing values (<1% of data).  \n","- **Action Taken:** **Dropped rows** where the product description was missing.  \n","- **Reason:** Product names cannot be reliably imputed, and incorrect product names would mislead product-level analysis.\n","\n","---\n","\n","#### **CustomerID Column**\n","- **Issue:** 135,080 missing values (~25% of data).  \n","- **Action Taken:** **Dropped rows** where CustomerID was missing.  \n","- **Reason:**  \n","  - Customer segmentation (e.g., RFM analysis) requires unique customer IDs.  \n","  - There is no logical way to impute CustomerIDs without introducing errors.  \n","  - Keeping these rows would create inaccurate customer groupings and insights.\n","\n","---\n","- For both **Description** and **CustomerID**, imputing missing values (like using \"Unknown\", mean, mode, etc.) would **distort the analysis**:\n","  - Incorrect CustomerIDs would merge unrelated customers or create duplicates.  \n","  - Random or placeholder product names would create fake products.  \n","- Since we have a **large dataset**, removing these rows does not significantly affect the analysis quality.\n"],"metadata":{"id":"1ixusLtI0pqI"}},{"cell_type":"markdown","source":["### 2. Handling Outliers"],"metadata":{"id":"id1riN9m0vUs"}},{"cell_type":"code","source":["# Handling Outliers & Outlier treatments\n","# Check shape before handling outliers\n","print(\"Original dataset shape:\", df.shape)\n","\n","# Separate returns (negative quantities) for future analysis\n","returns_df = df[df['Quantity'] < 0]\n","\n","# Remove invalid rows: Quantity <= 0 and UnitPrice <= 0\n","df = df[(df['Quantity'] > 0) & (df['UnitPrice'] > 0)]\n","\n","# Quantity\n","Q1 = df['Quantity'].quantile(0.25)\n","Q3 = df['Quantity'].quantile(0.75)\n","IQR = Q3 - Q1\n","lower_bound_q = Q1 - 1.5*IQR\n","upper_bound_q = Q3 + 1.5*IQR\n","df = df[(df['Quantity'] >= lower_bound_q) & (df['Quantity'] <= upper_bound_q)]\n","\n","# UnitPrice\n","Q1 = df['UnitPrice'].quantile(0.25)\n","Q3 = df['UnitPrice'].quantile(0.75)\n","IQR = Q3 - Q1\n","lower_bound_p = Q1 - 1.5*IQR\n","upper_bound_p = Q3 + 1.5*IQR\n","df = df[(df['UnitPrice'] >= lower_bound_p) & (df['UnitPrice'] <= upper_bound_p)]\n","\n","# Check shape after handling outliers\n","print(\"Cleaned dataset shape:\", df.shape)\n","print(\"Returns dataset shape (for separate analysis):\", returns_df.shape)\n"],"metadata":{"id":"M6w2CzZf04JK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### What all outlier treatment techniques have you used and why did you use those techniques?\n","\n","\n"],"metadata":{"id":"578E2V7j08f6"}},{"cell_type":"markdown","source":["#### Removing Invalid Data (Rule-Based Filtering)\n","- **What was done?**  \n","  - Removed rows where:\n","    - `Quantity <= 0` (invalid or returns)\n","    - `UnitPrice <= 0` (invalid price entries)\n","\n","  - Negative quantities or zero prices are not valid for revenue analysis.  \n","  - These records would distort total sales and customer value metrics.  \n","  - Returns (negative quantities) were separated into a different dataset for dedicated return analysis.\n","\n","---\n","\n","#### IQR Method (Interquartile Range)\n","- **What was done?**  \n","  - For both `Quantity` and `UnitPrice`, we calculated:  \n","    - **IQR = Q3 - Q1**  \n","    - **Lower Bound = Q1 - 1.5 × IQR**  \n","    - **Upper Bound = Q3 + 1.5 × IQR**  \n","  - Removed rows outside these bounds.\n","\n","  - Extreme high or low values distort averages and revenue calculations.  \n","  - The IQR method is a robust statistical approach that focuses on the middle 50% of the data and ignores extreme values.\n","\n","---\n"],"metadata":{"id":"uGZz5OrT1HH-"}},{"cell_type":"markdown","source":["### 3. Categorical Encoding"],"metadata":{"id":"89xtkJwZ18nB"}},{"cell_type":"code","source":["\n","# Identify categorical columns\n","categorical_cols = ['Country', 'Description']\n","\n","# Initialize Label Encoder\n","le = LabelEncoder()\n","\n","# Apply Label Encoding to each categorical column\n","for col in categorical_cols:\n","    df[col] = le.fit_transform(df[col])\n","\n","df.head()\n","\n","\n"],"metadata":{"id":"21JmIYMG2hEo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### What all categorical encoding techniques have you used & why did you use those techniques?"],"metadata":{"id":"67NQN5KX2AMe"}},{"cell_type":"markdown","source":["\n","- We used **Label Encoding** for the categorical columns `Country` and `Description`.\n","- This technique converts each unique category into a unique integer (e.g., `France → 1`, `Germany → 2`).\n","\n","  - `Description` has thousands of unique values; One-Hot Encoding would create too many columns.  \n","  - Label Encoding is **memory-efficient** and works well for clustering (unsupervised learning).\n"],"metadata":{"id":"UDaue5h32n_G"}},{"cell_type":"markdown","source":["## ***6. Feature Engineering***"],"metadata":{"id":"-oLEiFgy-5Pf"}},{"cell_type":"markdown","source":["#### 1. Calculating RFM"],"metadata":{"id":"C74aWNz2AliB"}},{"cell_type":"code","source":["import pandas as pd\n","\n","# Ensure InvoiceDate is in datetime format\n","df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])\n","\n","# Create TotalPrice feature (if not already created)\n","df['TotalPrice'] = df['Quantity'] * df['UnitPrice']\n","\n","# Get the latest purchase date in the dataset\n","latest_date = df['InvoiceDate'].max()\n","\n","# Group by CustomerID and calculate Recency, Frequency, and Monetary\n","rfm_df = df.groupby('CustomerID').agg({\n","    'InvoiceDate': lambda x: (latest_date - x.max()).days,   # Recency\n","    'TotalPrice': ['count', 'sum']                          # Frequency & Monetary\n","}).reset_index()\n","\n","# Rename multi-level columns\n","rfm_df.columns = ['CustomerID', 'Recency', 'Frequency', 'Monetary']\n","\n","# Display RFM DataFrame\n","rfm_df.head()\n","\n"],"metadata":{"id":"h1qC4yhBApWC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 2.  Data Scaling"],"metadata":{"id":"2DejudWSA-a0"}},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","\n","# Select only the RFM columns for scaling\n","rfm_features = rfm_df[['Recency', 'Frequency', 'Monetary']]\n","\n","# Initialize the StandardScaler\n","scaler = StandardScaler()\n","\n","# Fit and transform the RFM data\n","rfm_scaled = scaler.fit_transform(rfm_features)\n","\n","# Convert back to a DataFrame with the same column names\n","rfm_scaled_df = pd.DataFrame(rfm_scaled, columns=['Recency', 'Frequency', 'Monetary'])\n","\n","# Add back CustomerID for reference\n","rfm_scaled_df['CustomerID'] = rfm_df['CustomerID'].values\n","\n","rfm_scaled_df.head()\n"],"metadata":{"id":"pDEq8Vo020z4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 3. Using Elbow Method , Silhouette Score to decide the number of clusters\n"],"metadata":{"id":"djfSLWQixq5d"}},{"cell_type":"code","source":["from sklearn.cluster import KMeans\n","from sklearn.metrics import silhouette_score\n","\n","inertia = []\n","silhouette_scores = []\n","k_values = range(2, 11)\n","\n","for k in k_values:\n","    kmeans = KMeans(n_clusters=k, random_state=42)\n","    kmeans.fit(rfm_scaled_df[['Recency', 'Frequency', 'Monetary']])\n","    inertia.append(kmeans.inertia_)  # WCSS\n","    silhouette_scores.append(silhouette_score(\n","        rfm_scaled_df[['Recency', 'Frequency', 'Monetary']], kmeans.labels_))\n","\n","# Plot Elbow Method\n","plt.figure(figsize=(8,4))\n","plt.plot(k_values, inertia, marker='o')\n","plt.title('Elbow Method (WCSS)')\n","plt.xlabel('Number of Clusters (k)')\n","plt.ylabel('WCSS')\n","plt.show()\n","\n","# Plot Silhouette Score\n","plt.figure(figsize=(8,4))\n","plt.plot(k_values, silhouette_scores, marker='o', color='green')\n","plt.title('Silhouette Score')\n","plt.xlabel('Number of Clusters (k)')\n","plt.ylabel('Silhouette Score')\n","plt.show()\n"],"metadata":{"id":"euNKlkzGxHjK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 4. Clustering Algorithm (KMeans, DBScan, Hierarchial etc)\n"],"metadata":{"id":"d8dWL0h5y2Da"}},{"cell_type":"code","source":["from sklearn.cluster import KMeans\n","\n","# Run K-Means with an initial guess of k=4\n","kmeans = KMeans(n_clusters=4, random_state=42)\n","rfm_scaled_df['Cluster'] = kmeans.fit_predict(rfm_scaled_df[['Recency', 'Frequency', 'Monetary']])\n","\n","# Show the first few rows with assigned clusters\n","rfm_scaled_df.head()"],"metadata":{"id":"UrLwSyIQy1o9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 5. Visualize the cluster in 2-D plot"],"metadata":{"id":"ssPg3HF8x5g3"}},{"cell_type":"code","source":["# Run K-Means with optimal k\n","kmeans = KMeans(n_clusters=4, random_state=42)\n","rfm_scaled_df['Cluster'] = kmeans.fit_predict(rfm_scaled_df[['Recency', 'Frequency', 'Monetary']])\n","\n","# Now plot\n","plt.figure(figsize=(8,6))\n","plt.scatter(rfm_scaled_df['Recency'], rfm_scaled_df['Monetary'],\n","            c=rfm_scaled_df['Cluster'], cmap='viridis', s=50, alpha=0.7)\n","plt.title('Customer Segments (Recency vs Monetary)')\n","plt.xlabel('Recency (Standardized)')\n","plt.ylabel('Monetary (Standardized)')\n","plt.colorbar(label='Cluster')\n","plt.show()\n"],"metadata":{"id":"ef0LNjYY1dvH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["####6. Visualize the cluster in 3-D Plot"],"metadata":{"id":"lJhEyKplyA4N"}},{"cell_type":"code","source":["fig = plt.figure(figsize=(10,8))\n","ax = fig.add_subplot(111, projection='3d')\n","\n","x = rfm_scaled_df['Recency']\n","y = rfm_scaled_df['Frequency']\n","z = rfm_scaled_df['Monetary']\n","clusters = rfm_scaled_df['Cluster']\n","\n","sc = ax.scatter(x, y, z, c=clusters, cmap='viridis', s=50, alpha=0.7)\n","\n","ax.set_title('3D Customer Segments (RFM)')\n","ax.set_xlabel('Recency (Standardized)')\n","ax.set_ylabel('Frequency (Standardized)')\n","ax.set_zlabel('Monetary (Standardized)')\n","fig.colorbar(sc, label='Cluster')\n","plt.show()\n"],"metadata":{"id":"SeNabW011xrA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 7. Building Customer-Product Matrix"],"metadata":{"id":"STKlBphm0vi3"}},{"cell_type":"code","source":["# Create a pivot table: customers vs products (Quantity as values)\n","customer_product_matrix = df.pivot_table(\n","    index='CustomerID',\n","    columns='Description',\n","    values='Quantity',\n","    aggfunc='sum',\n","    fill_value=0\n",")\n","\n","customer_product_matrix.head()\n"],"metadata":{"id":"LenrzVoqzwfM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 8. Computing Product Similarity (Cosine Similarity)"],"metadata":{"id":"jWyKzr-e0pay"}},{"cell_type":"code","source":["from sklearn.metrics.pairwise import cosine_similarity\n","import pandas as pd\n","\n","# Transpose the matrix to get products as rows\n","product_similarity = cosine_similarity(customer_product_matrix.T)\n","\n","# Convert to a DataFrame\n","product_similarity_df = pd.DataFrame(\n","    product_similarity,\n","    index=customer_product_matrix.columns,\n","    columns=customer_product_matrix.columns\n",")\n","\n","product_similarity_df.head()\n"],"metadata":{"id":"VnQGWOlJzzev"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 9.  Ploting Heatmap of Product Similarity"],"metadata":{"id":"v0fndYez06mI"}},{"cell_type":"code","source":["import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","plt.figure(figsize=(12,8))\n","sns.heatmap(product_similarity_df.iloc[:20, :20], cmap='viridis')  # Show top 20 products\n","plt.title(\"Product Similarity Heatmap\")\n","plt.show()\n"],"metadata":{"id":"c72rlYdbz3Et"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Conclusion**"],"metadata":{"id":"gCX9965dhzqZ"}},{"cell_type":"markdown","source":["\n","This project utilized **RFM Analysis** and **K-Means Clustering** to segment customers based on their purchasing behavior. After extensive preprocessing, feature engineering, and scaling:  \n","\n","1. We identified **optimal customer clusters (k=4)** using the **Elbow Method** and **Silhouette Score**.  \n","2. Each cluster represents a unique customer group:  \n","   - **High-value frequent customers** (loyal and profitable)  \n","   - **Moderate-value customers** (can be nurtured further)  \n","   - **One-time/occasional customers** (require engagement campaigns)  \n","   - **Dormant or low-value customers** (likely to churn)  \n","3. Visualizations such as **top products, country-wise transactions, purchase trends, and monetary distributions** provided deeper business insights.  \n","4. These insights enable businesses to:  \n","   - **Target the right customers** with personalized offers.  \n","   - **Improve retention** by focusing on loyal and at-risk customers.  \n","   - **Optimize marketing spend** by segmenting the audience effectively.  \n","\n","This segmentation lays a strong foundation for **data-driven customer relationship management (CRM)** and can be extended to **product recommendations** using **customer-product similarity matrices** for further personalization.\n"],"metadata":{"id":"Fjb1IsQkh3yE"}},{"cell_type":"markdown","source":["### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"],"metadata":{"id":"gIfDvo9L0UH2"}}]}